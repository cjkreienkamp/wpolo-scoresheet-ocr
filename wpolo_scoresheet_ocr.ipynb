{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cjkreienkamp/wpolo-scoresheet-ocr/blob/main/wpolo_scoresheet_ocr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. rotate image using lines\n",
        "2. read in cap data\n",
        "3. read in team data\n",
        "4. read in remark\n",
        "5. read in score\n",
        "6. read in time\n",
        "7. read in column\n",
        "8. read in entire game log\n",
        "9. locate position on page by comparing it to other game sheets, we should have an expected size for that area"
      ],
      "metadata": {
        "id": "Mfwbqo2tPzAe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Configure Environment"
      ],
      "metadata": {
        "id": "i2Ji6g4hMqSY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0.1 Imports"
      ],
      "metadata": {
        "id": "7x0uDUxG9xxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import imutils\n",
        "from imutils import contours\n",
        "import os\n",
        "import torch\n",
        "from typing import Dict, List\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import pathlib"
      ],
      "metadata": {
        "id": "BgtsKJ9cMu4U"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0.2 Create folder structure"
      ],
      "metadata": {
        "id": "WbrBUfIg9QXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('output'): os.makedirs('output')\n",
        "if not os.path.exists('output/ROI'): os.makedirs('output/ROI')\n",
        "for i in range(1, 76):\n",
        "  if not os.path.exists(f'output/ROI/{i}'): os.makedirs(f'output/ROI/{i}')"
      ],
      "metadata": {
        "id": "BvPUWEP79Uv_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Align the scoresheet to its template"
      ],
      "metadata": {
        "id": "RFg3pw9SQNGR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.0 Functions"
      ],
      "metadata": {
        "id": "Jq63EE83MMrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import groupby, product\n",
        "from typing import List, Tuple\n",
        "from collections import defaultdict\n",
        "\n",
        "def align_images(image, template, maxFeatures=500, keepPercent=0.2, debug=False):\n",
        "\timage_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\ttemplate_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        " \t# detect keypoints and extract features\n",
        "\torb = cv2.ORB_create(maxFeatures)\n",
        "\t(keyptsA, descsA) = orb.detectAndCompute(image_gray, None)\n",
        "\t(keyptsB, descsB) = orb.detectAndCompute(template_gray, None)\n",
        "\n",
        "\t# match the features\n",
        "\tmethod = cv2.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING\n",
        "\tmatcher = cv2.DescriptorMatcher_create(method)\n",
        "\tmatches = matcher.match(descsA, descsB, None)\n",
        "\n",
        " \t# sort the matches by their distance (smaller distance = \"more similar\")\n",
        "\tmatches = sorted(matches, key=lambda x:x.distance)\n",
        "\tkeep = int(len(matches) * keepPercent)\n",
        "\tmatches = matches[:keep]\n",
        "\n",
        "  # allocate memory for the keypoints (x, y)-coordinates from the\n",
        "\t# top matches -- use these coordinates to compute homography matrix\n",
        "\tptsA = np.zeros((len(matches), 2), dtype=\"float\")\n",
        "\tptsB = np.zeros((len(matches), 2), dtype=\"float\")\n",
        "\t# loop over the top matches\n",
        "\tfor (i, m) in enumerate(matches):\n",
        "\t\t# indicate that the two keypoints in the respective images\n",
        "\t\t# map to each other\n",
        "\t\tptsA[i] = keyptsA[m.queryIdx].pt\n",
        "\t\tptsB[i] = keyptsB[m.trainIdx].pt\n",
        "\n",
        "\t(H, mask) = cv2.findHomography(ptsA, ptsB, method=cv2.RANSAC)\n",
        "\t(h, w) = template.shape[:2]\n",
        "\taligned = cv2.warpPerspective(image, H, (w, h))\n",
        "\treturn aligned\n",
        "\n",
        "def segment_by_angle_kmeans(lines, k=2, **kwargs):\n",
        "\t\"\"\"Groups lines based on angle with k-means.\n",
        "\n",
        "\tUses k-means on the coordinates of the angle on the unit circle\n",
        "\tto segment `k` angles inside `lines`.\n",
        "\t\"\"\"\n",
        "\n",
        "\t# Define criteria = (type, max_iter, epsilon)\n",
        "\tdefault_criteria_type = cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER\n",
        "\tcriteria = kwargs.get('criteria', (default_criteria_type, 10, 1.0))\n",
        "\tflags = kwargs.get('flags', cv2.KMEANS_RANDOM_CENTERS)\n",
        "\tattempts = kwargs.get('attempts', 10)\n",
        "\n",
        "\t# returns angles in [0, pi] in radians\n",
        "\tangles = np.array([line[0][1] for line in lines])\n",
        "\t# multiply the angles by two and find coordinates of that angle\n",
        "\tpts = np.array([[np.cos(2*angle), np.sin(2*angle)]\n",
        "\t\t\t\t\t\t\t\t\tfor angle in angles], dtype=np.float32)\n",
        "\n",
        "\t# run kmeans on the coords\n",
        "\tlabels, centers = cv2.kmeans(pts, k, None, criteria, attempts, flags)[1:]\n",
        "\tlabels = labels.reshape(-1)  # transpose to row vec\n",
        "\n",
        "\t# segment lines based on their kmeans label\n",
        "\tsegmented = defaultdict(list)\n",
        "\tfor i, line in enumerate(lines):\n",
        "\t\t\tsegmented[labels[i]].append(line)\n",
        "\tsegmented = list(segmented.values())\n",
        "\treturn segmented\n",
        "\n",
        "def intersection(line1, line2):\n",
        "\t\"\"\"Finds the intersection of two lines given in Hesse normal form.\n",
        "\n",
        "\tReturns closest integer pixel locations.\n",
        "\tSee https://stackoverflow.com/a/383527/5087436\n",
        "\t\"\"\"\n",
        "\trho1, theta1 = line1[0]\n",
        "\trho2, theta2 = line2[0]\n",
        "\tA = np.array([\n",
        "\t\t\t[np.cos(theta1), np.sin(theta1)],\n",
        "\t\t\t[np.cos(theta2), np.sin(theta2)]\n",
        "\t])\n",
        "\tb = np.array([[rho1], [rho2]])\n",
        "\tx0, y0 = np.linalg.solve(A, b)\n",
        "\tx0, y0 = int(np.round(x0)), int(np.round(y0))\n",
        "\treturn [x0, y0]\n",
        "\n",
        "\n",
        "def segmented_intersections(lines):\n",
        "  \"\"\"Finds the intersections between groups of lines.\"\"\"\n",
        "\n",
        "  intersections = []\n",
        "  for i, group in enumerate(lines[:-1]):\n",
        "      for next_group in lines[i+1:]:\n",
        "          for line1 in group:\n",
        "              for line2 in next_group:\n",
        "                  intersections.append(intersection(line1, line2))\n",
        "\n",
        "  return intersections\n",
        "\n",
        "def Manhattan(tup1, tup2):\n",
        "  return abs(tup1[0] - tup2[0]) + abs(tup1[1] - tup2[1])\n",
        "\n",
        "def groupSimilarPoints(points):\n",
        "  points = [tuple(point) for point in points]\n",
        "  man_tups = [sorted(sub) for sub in product(points, repeat = 2)\n",
        "                                        if Manhattan(*sub) < 5]\n",
        "  groups_dict = {ele: {ele} for ele in points}\n",
        "  for tup1, tup2 in man_tups:\n",
        "    groups_dict[tup1] |= groups_dict[tup2]\n",
        "    groups_dict[tup2] = groups_dict[tup1]\n",
        "\n",
        "  groups = [[*next(val)] for key, val in groupby(\n",
        "      sorted(groups_dict.values(), key = id), id)]\n",
        "\n",
        "  result = []\n",
        "  for group in groups:\n",
        "    if len(group) < 5: continue\n",
        "    average = [sum(point)/len(point) for point in zip(*group)]\n",
        "    average[0] = int(average[0])\n",
        "    average[1] = int(average[1])\n",
        "    result.append(average)\n",
        "  result = sorted(result, key=lambda x: (x[1],x[0]))\n",
        "  return result\n",
        "\n",
        "def distance(pointA, pointB):\n",
        "  return np.sqrt((pointA[0] - pointB[0])**2 + (pointA[1] - pointB[1])**2)"
      ],
      "metadata": {
        "id": "qVf4Yp2EQMIG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Align the scoresheet"
      ],
      "metadata": {
        "id": "5vo1DAEMMR6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scoresheet = cv2.imread('/content/drive/MyDrive/input/scoresheet1.png')\n",
        "scoresheet_template = cv2.imread('/content/drive/MyDrive/input/scoresheet_template.png')\n",
        "scoresheet_aligned = align_images(scoresheet, scoresheet_template, debug=True)\n",
        "cv2.imwrite('output/scoresheet_aligned.png',scoresheet_aligned)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gAwdapsVbHK",
        "outputId": "70d4c7b5-7a12-4430-957d-c8aeeddc0ea9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Identify first column of the gamelog on the aligned scoresheet"
      ],
      "metadata": {
        "id": "Q0cOhHvnvgR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(scoresheet_aligned_height, scoresheet_aligned_width) = scoresheet_aligned.shape[:2]\n",
        "top_left_gamelog = (int(scoresheet_aligned_width*0.005), int(scoresheet_aligned_height*0.6405))\n",
        "bottom_right_gamelog = (int(scoresheet_aligned_width*0.79), int(scoresheet_aligned_height*0.995))\n",
        "\n",
        "scoresheet_bb_gamelog = scoresheet_aligned.copy()\n",
        "cv2.rectangle(scoresheet_bb_gamelog, top_left_gamelog, bottom_right_gamelog, (0, 0, 255), 3)\n",
        "#cv2.imwrite('output/scoresheet_bb_gamelog.png',scoresheet_bb_gamelog)\n",
        "gamelog = scoresheet_aligned[top_left_gamelog[1]:bottom_right_gamelog[1], top_left_gamelog[0]:bottom_right_gamelog[0]]\n",
        "#cv2.imwrite('output/gamelog.png',gamelog)\n",
        "\n",
        "(gamelog_height, gamelog_width) = gamelog.shape[:2]\n",
        "top_left_col1 = (0, 0)\n",
        "bottom_right_col1 = (int(gamelog_width*0.225), gamelog_height)\n",
        "\n",
        "gamelog_bb_col1 = gamelog.copy()\n",
        "cv2.rectangle(gamelog_bb_col1, top_left_col1, bottom_right_col1, (0, 0, 255), 3)\n",
        "#cv2.imwrite('output/gamelog_bb_col1.png',gamelog_bb_col1)\n",
        "col1 = gamelog[top_left_col1[1]:bottom_right_col1[1], top_left_col1[0]:bottom_right_col1[0]]\n",
        "#cv2.imwrite('output/col1.png',col1)"
      ],
      "metadata": {
        "id": "KmRliCz4voun"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Align first column of the gamelog"
      ],
      "metadata": {
        "id": "p4eR-9p9uiMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "col1_corners = col1.copy()\n",
        "col1_gray = cv2.cvtColor(col1, cv2.COLOR_BGR2GRAY)\n",
        "col1_gray = np.float32(col1_gray)\n",
        "dst = cv2.cornerHarris(col1_gray,2,3,0.04)\n",
        "dst = cv2.dilate(dst,None)\n",
        "col1_corners[dst>0.01*dst.max()]=[0,0,255]\n",
        "#cv2.imwrite('output/col1_corners.png',col1_corners)\n",
        "\n",
        "col1_gray = col1.copy()\n",
        "col1_gray = cv2.cvtColor(col1_gray, cv2.COLOR_BGR2GRAY)\n",
        "_, col1_modified = cv2.threshold(col1_gray, 128, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "col1_canny = cv2.Canny(col1_modified, 100, 200, None, 3)\n",
        "col1_lines = cv2.HoughLines(col1_canny, 1 , np.pi/180 , 150)\n",
        "#cv2.imwrite('output/col1_gray.png',col1_gray)\n",
        "#cv2.imwrite('output/col1_canny.png',col1_canny)\n",
        "\n",
        "segmented_lines = segment_by_angle_kmeans(col1_lines)\n",
        "intersections = segmented_intersections(segmented_lines)\n",
        "grouped_intersections = groupSimilarPoints(intersections)\n",
        "\n",
        "(col1_height, col1_width) = col1.shape[:2]\n",
        "tl = (col1_height/2,col1_width/2)\n",
        "bl = (col1_height/2,col1_width/2)\n",
        "tr = (col1_height/2,col1_width/2)\n",
        "br = (col1_height/2,col1_width/2)\n",
        "\n",
        "col1_w_intersections = col1.copy()\n",
        "for point in grouped_intersections:\n",
        "  tl = point if distance((0,0), point) < distance(tl, (0,0)) else tl\n",
        "  bl = [point[0] - 5, point[1] + 8] if distance((0,col1_height), point) < distance(bl, (0,col1_height)) else bl\n",
        "  tr = [point[0] + 10, point[1]] if distance((col1_width,0), point) < distance(tr, (col1_width,0)) else tr\n",
        "  br = [point[0] + 6, point[1] + 8] if distance((col1_width,col1_height), point) < distance(br, (col1_width,col1_height)) else br\n",
        "  cv2.circle(col1_w_intersections, point, 2, (255, 0, 0), -1)\n",
        "for col_corner in [tl, bl, tr, br]:\n",
        "  cv2.circle(col1_w_intersections, col_corner, 2, (0, 0, 255), -1)\n",
        "#cv2.imwrite('output/col1_w_intersections.png',col1_w_intersections)\n",
        "\n",
        "col_template = cv2.imread('/content/drive/MyDrive/input/col_template.png')\n",
        "(col_template_height, col_template_width) = col_template.shape[:2]\n",
        "pts_src = np.array([tl, bl, tr, br])\n",
        "pts_dst = np.array([[0,0],[0,col_template_height],[col_template_width,0],[col_template_width,col_template_height]])\n",
        "h, mask = cv2.findHomography(pts_src, pts_dst)\n",
        "col1_aligned = cv2.warpPerspective(col1, h, (col_template_width, col_template_height))\n",
        "cv2.imwrite('output/col1_aligned.png',col1_aligned)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUxa1EqAOX0W",
        "outputId": "36d7732b-bd79-447e-f56a-c06960a5fc56"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-6871825d419c>:84: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  x0, y0 = int(np.round(x0)), int(np.round(y0))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Identify contours within each cell\n",
        "\n",
        "1. TIME: separate the numbers\n",
        "2. CAP#: separate the numbers\n",
        "3. TEAM: find one contour\n",
        "4. REMARKS: find one contour\n",
        "5. D-W: separate the numbers"
      ],
      "metadata": {
        "id": "sDtfiwBMsdvd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Identify every cell of the first gamelog column"
      ],
      "metadata": {
        "id": "jb93gOdHQKfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "col_template = cv2.imread('/content/drive/MyDrive/input/col_template.png')\n",
        "col_template_gray = cv2.cvtColor(col_template, cv2.COLOR_BGR2GRAY)\n",
        "_, col_template_bin = cv2.threshold(col_template_gray, 128, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "col_edges = cv2.Canny(col_template_bin, 100, 200, None, 3)\n",
        "col_edges = cv2.bitwise_not(col_edges)\n",
        "col_erode = cv2.erode(col_edges, None, iterations=2)\n",
        "col_contours = cv2.findContours(col_erode, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "col_contours = col_contours[0] if len(col_contours) == 2 else col_contours[1]\n",
        "col_contours = [sorted(contour.tolist(), reverse=True) for contour in col_contours if contour[0][0][1]>col_template_height/17]\n",
        "#cv2.drawContours(col_template, col_contours, -1, (0, 255, 0), 1)\n",
        "\n",
        "ROI_number = 0\n",
        "cell_height = 0\n",
        "cell_width = 0\n",
        "col1_bb = col1_aligned.copy()\n",
        "for c in col_contours:\n",
        "  ROI_number += 1\n",
        "  if ROI_number > 75: break\n",
        "  x,y,w,h = cv2.boundingRect(np.array(c))\n",
        "  (cell_height, cell_width) = (h, w)\n",
        "  cv2.rectangle(col1_bb, (x-3, y-3), (x+w+3, y+h+3), (36,255,12), 2)\n",
        "  cv2.rectangle(col_template, (x-3, y-3), (x+w+3, y+h+3), (36,255,12), 2)\n",
        "  cv2.putText(col1_bb, str(ROI_number), (int(x+w/3), int(y+h*2/3)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 1)\n",
        "  ROI_image = col1_aligned[y:y+h, x:x+w]\n",
        "  cv2.imwrite(f'output/ROI/{ROI_number}/cell.png',ROI_image)\n",
        "\n",
        "#cv2.imwrite('output/col_template.png',col_template)\n",
        "cv2.imwrite('output/col1_bb.png',col1_bb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lbp2o7uxOsKj",
        "outputId": "66f2350b-81c4-4e7d-fd45-17dd4032cb32"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Find the bounding-box for every contour in a cell, separating each digit/number"
      ],
      "metadata": {
        "id": "f5mwR4U3nn9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ROI_gray_list = []\n",
        "for ROI_number in range(1, 76):\n",
        "  ROI_image = cv2.imread(f'output/ROI/{ROI_number}/cell.png')\n",
        "  gray = cv2.cvtColor(ROI_image, cv2.COLOR_BGR2GRAY)\n",
        "  binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n",
        "  border = cv2.copyMakeBorder(binary,top=10,bottom=10,left=10,right=10,borderType=cv2.BORDER_CONSTANT,value=[255,255,255])\n",
        "  erode = cv2.erode(border, None, iterations=1)\n",
        "  (cnts, hiers) = cv2.findContours(erode.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  hiers = hiers[0]\n",
        "  #cnts = imutils.grab_contours(cnts)\n",
        "  #cnts = contours.sort_contours(cnts, method=\"left-to-right\")[0]\n",
        "\n",
        "  ROI_image = cv2.copyMakeBorder(ROI_image,top=10,bottom=10,left=10,right=10,borderType=cv2.BORDER_REPLICATE)\n",
        "  contour_number = 0\n",
        "  for (cnt, hier) in zip(cnts,hiers):\n",
        "    if hier[3] != 0: continue\n",
        "    if cv2.contourArea(cnt) > 800: continue\n",
        "    #minx = min(cnt.reshape(-1, 2)[:, 0])\n",
        "    (x, y, w, h) = cv2.boundingRect(cnt)\n",
        "    if h < 15: continue\n",
        "    roi = ROI_image[y:y + h, x:x + w]\n",
        "    cv2.rectangle(ROI_image, (x, y), (x + w, y + h), (36,255,12), 2)\n",
        "    contour_image = ROI_image[y:y+h, x:x+w]\n",
        "    contour_number += 1\n",
        "    cv2.imwrite(f'output/ROI/{ROI_number}/contour{contour_number}.png',contour_image)\n",
        "  cv2.imwrite(f'output/ROI/{ROI_number}/cell_w_bb.png',ROI_image)"
      ],
      "metadata": {
        "id": "L5SjOOCwwirm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Classify each cell\n",
        "\n",
        "1. TIME: MNIST\n",
        "2. CAP#: MNIST\n",
        "3. TEAM: D or W\n",
        "4. REMARKS: 13 classes\n",
        "5. D-W: MNIST"
      ],
      "metadata": {
        "id": "x9rlD5pcOkTq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.0 Functions"
      ],
      "metadata": {
        "id": "oYTtfimM-YLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_number(model: torch.nn.Module,\n",
        "                        image_path: str,\n",
        "                        class_names: List[str] = None,\n",
        "                        transform=None):\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    target_image = torchvision.io.read_image(str(image_path)).type(torch.float32)\n",
        "    target_image = target_image / 255.\n",
        "\n",
        "    target_image = transforms.functional.resize(target_image, (28, 28))\n",
        "    target_image = transforms.functional.rgb_to_grayscale(target_image, num_output_channels=1)\n",
        "\n",
        "    if transform:\n",
        "        target_image = transform(target_image)\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        target_image = target_image.unsqueeze(dim=0) # add an extra dimension to image\n",
        "        target_image_pred = model(target_image.to(device))\n",
        "\n",
        "    target_image_pred_probs = torch.softmax(target_image_pred, dim=1) # convert logits --> prediction probabilities\n",
        "    target_image_pred_label = torch.argmax(target_image_pred_probs, dim=1) # convert prediction probabilities --> prediction labels\n",
        "    return (f'{class_names[target_image_pred_label.cpu()]} ({target_image_pred_probs.max().cpu():.3f})')"
      ],
      "metadata": {
        "id": "_8aQZB8pHSRi"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Load model and dataset"
      ],
      "metadata": {
        "id": "KqT2sxeH-dn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_0 = torch.jit.load('/content/drive/MyDrive/input/mnist_model.pt')\n",
        "\n",
        "dataset = torchvision.datasets.MNIST(\n",
        "    root='./',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor())"
      ],
      "metadata": {
        "id": "l74b9qvKG73-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af01d1a8-120e-4d67-8aeb-2d015536d278"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 73501940.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 41598795.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 32872549.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 7565738.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UohtATdsU9R",
        "outputId": "42407227-2cb8-4870-e7a4-faf52ffebf33"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Make prediction on one image"
      ],
      "metadata": {
        "id": "rypylfd2_RRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = predict_number(model=model_0,\n",
        "               image_path=f'output/ROI/1/contour2.png',\n",
        "               class_names=dataset.classes,\n",
        "               transform=None)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18q-o6m1xK9m",
        "outputId": "e3307349-1db9-4f92-dfa4-d77579d4bc53"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 - five, 0.995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Make prediction on all images"
      ],
      "metadata": {
        "id": "Lk_SXYrWiIQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for cell in range(1, 76):\n",
        "  if ( cell - 1 ) % 5 in [0, 3, 4]:\n",
        "    i = 0\n",
        "    print(f'{cell}: ',end='')\n",
        "    for path in os.listdir(f'output/ROI/{cell}'):\n",
        "      i += 1\n",
        "      if 'contour' in path:\n",
        "        output = predict_number(model=model_0,\n",
        "                       image_path=f'output/ROI/{cell}/{path}',\n",
        "                       class_names=[0,1,2,3,4,5,6,7,8,9],\n",
        "                       transform=None)\n",
        "        print(f'{output}   ',end='')\n",
        "    if i==2:\n",
        "      print(f'EMPTY',end='')\n",
        "    print()"
      ],
      "metadata": {
        "id": "_FOQEK5LEHuO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ea8b9f2-c412-4d8f-c1d4-bc7ad7ac2258"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: 5 (0.995)   5 (0.394)   \n",
            "4: 5 (0.727)   5 (0.988)   \n",
            "5: 2 (0.652)   5 (0.999)   \n",
            "6: EMPTY\n",
            "9: EMPTY\n",
            "10: 3 (0.686)   \n",
            "11: EMPTY\n",
            "14: 2 (0.807)   2 (0.914)   \n",
            "15: 2 (0.441)   5 (0.983)   \n",
            "16: EMPTY\n",
            "19: 5 (0.784)   2 (0.884)   \n",
            "20: 3 (0.717)   2 (0.999)   \n",
            "21: EMPTY\n",
            "24: 5 (0.962)   \n",
            "25: 2 (0.945)   2 (0.989)   \n",
            "26: EMPTY\n",
            "29: 5 (0.625)   5 (0.966)   \n",
            "30: 2 (0.822)   5 (0.768)   5 (0.979)   \n",
            "31: EMPTY\n",
            "34: EMPTY\n",
            "35: 2 (0.981)   5 (0.997)   5 (0.959)   \n",
            "36: EMPTY\n",
            "39: 5 (0.953)   5 (0.553)   \n",
            "40: 5 (0.698)   2 (0.873)   2 (0.591)   \n",
            "41: 2 (0.928)   5 (0.719)   \n",
            "44: 5 (0.990)   \n",
            "45: 3 (0.682)   5 (0.483)   2 (0.591)   \n",
            "46: 5 (0.703)   \n",
            "49: 5 (0.955)   \n",
            "50: 2 (0.661)   3 (0.940)   \n",
            "51: 5 (0.830)   \n",
            "54: 5 (0.992)   \n",
            "55: EMPTY\n",
            "56: EMPTY\n",
            "59: 5 (0.563)   5 (0.976)   \n",
            "60: 5 (0.997)   5 (0.977)   5 (0.928)   5 (0.980)   \n",
            "61: EMPTY\n",
            "64: 5 (0.978)   \n",
            "65: 5 (0.705)   2 (0.985)   2 (0.868)   \n",
            "66: 2 (0.533)   2 (0.535)   \n",
            "69: 2 (0.652)   2 (0.684)   \n",
            "70: 5 (0.996)   2 (0.512)   5 (0.478)   \n",
            "71: 2 (0.998)   2 (0.865)   \n",
            "74: 5 (0.997)   \n",
            "75: 2 (0.655)   2 (0.929)   5 (0.937)   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## To Do:\n",
        "* retrain MNIST\n",
        "* re-number the cells\n",
        "* get the rest of the columns\n",
        "* test on other scoresheets\n",
        "* add HC to MNIST and retrain\n",
        "\n"
      ],
      "metadata": {
        "id": "JNpdXdbluIqH"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "i2Ji6g4hMqSY",
        "7x0uDUxG9xxD",
        "WbrBUfIg9QXC",
        "RFg3pw9SQNGR",
        "Jq63EE83MMrE",
        "5vo1DAEMMR6y",
        "Q0cOhHvnvgR3",
        "p4eR-9p9uiMd",
        "sDtfiwBMsdvd",
        "jb93gOdHQKfp",
        "f5mwR4U3nn9z",
        "oYTtfimM-YLG",
        "KqT2sxeH-dn0",
        "Lk_SXYrWiIQz"
      ],
      "mount_file_id": "1ywFbjldTqul6UzMEJaJlpSxrzGUut4CJ",
      "authorship_tag": "ABX9TyNzlgBMy4I4KFMqmOZiwDrY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}